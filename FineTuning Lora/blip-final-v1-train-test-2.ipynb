{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11629593,"sourceType":"datasetVersion","datasetId":7296443},{"sourceId":11645228,"sourceType":"datasetVersion","datasetId":7307471},{"sourceId":11676506,"sourceType":"datasetVersion","datasetId":7328450},{"sourceId":11676725,"sourceType":"datasetVersion","datasetId":7328608}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers datasets peft torch accelerate pillow bitsandbytes # bitsandbytes often needed for efficient loading","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T12:53:57.926733Z","iopub.execute_input":"2025-05-07T12:53:57.927021Z","iopub.status.idle":"2025-05-07T12:54:01.691048Z","shell.execute_reply.started":"2025-05-07T12:53:57.927003Z","shell.execute_reply":"2025-05-07T12:54:01.689968Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.1)\nRequirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.0)\nRequirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.14.0)\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\nRequirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.3.0)\nRequirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.1.0)\nRequirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (0.45.5)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.3)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.16)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft) (7.0.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.2.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.19.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import os\nimport json\nimport torch\nfrom PIL import Image\nfrom torch.utils.data import Dataset, DataLoader, random_split\nfrom transformers import Blip2ForConditionalGeneration, Blip2Processor, TrainingArguments, Trainer\nfrom peft import get_peft_model, LoraConfig, TaskType","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T12:54:05.080898Z","iopub.execute_input":"2025-05-07T12:54:05.081240Z","iopub.status.idle":"2025-05-07T12:54:13.262283Z","shell.execute_reply.started":"2025-05-07T12:54:05.081213Z","shell.execute_reply":"2025-05-07T12:54:13.261577Z"}},"outputs":[{"name":"stderr","text":"2025-05-07 12:54:09.106257: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1746622449.133631     210 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1746622449.141878     210 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"class VQADataset(Dataset):\n    def __init__(self, json_dirs, base_img_path, processor):\n        self.samples = []\n        self.processor = processor\n        self.base_img_path = base_img_path\n\n        print(f\"📁 Scanning JSON folders: {json_dirs}\")\n\n        for dir_path in ([json_dirs] if isinstance(json_dirs, str) else json_dirs):\n            for root, _, files in os.walk(dir_path):\n                for file in files:\n                    if file.endswith(\".json\"):\n                        json_path = os.path.join(root, file)\n                        with open(json_path, \"r\") as f:\n                            data = json.load(f)\n\n                        image_rel_path = data[\"image_path\"].replace(\"\\\\\", \"/\")\n\n                        # Remove everything before and including 'abo-images-small/'\n                        if \"abo-images-small/\" in image_rel_path:\n                            image_rel_path = image_rel_path.split(\"abo-images-small/\", 1)[1]\n\n                        image_path = os.path.join(base_img_path, image_rel_path)\n\n                        for qa in data[\"qa_pairs\"]:\n                            self.samples.append({\n                                \"image_path\": image_path,\n                                \"question\": qa[\"question\"],\n                                \"answer\": qa[\"answer\"]\n                            })\n\n        print(f\"✅ Loaded {len(self.samples)} samples.\")\n\n    def __len__(self):\n        return len(self.samples)\n\n    def __getitem__(self, idx):\n        sample = self.samples[idx]\n        image = Image.open(sample[\"image_path\"]).convert(\"RGB\")\n\n        inputs = self.processor(\n            images=image,\n            text=sample[\"question\"],\n            return_tensors=\"pt\",\n            padding=\"max_length\",\n            truncation=True,\n            max_length=128\n        )\n\n        labels = self.processor.tokenizer(\n            sample[\"answer\"],\n            return_tensors=\"pt\",\n            padding=\"max_length\",\n            truncation=True,\n            max_length=10\n        ).input_ids\n\n        inputs = {k: v.squeeze(0) for k, v in inputs.items()}\n        inputs[\"labels\"] = labels.squeeze(0)\n\n        # Remove inputs_embeds if it exists\n        if \"inputs_embeds\" in inputs:\n            del inputs[\"inputs_embeds\"]\n\n        return inputs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T12:54:17.864507Z","iopub.execute_input":"2025-05-07T12:54:17.864863Z","iopub.status.idle":"2025-05-07T12:54:17.874525Z","shell.execute_reply.started":"2025-05-07T12:54:17.864837Z","shell.execute_reply":"2025-05-07T12:54:17.873522Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def compute_metrics(pred):\n    preds = pred.predictions\n    labels = pred.label_ids\n\n    tokenizer = Blip2Processor.from_pretrained(\"Salesforce/blip-vqa-base\").tokenizer\n    pred_texts = tokenizer.batch_decode(preds, skip_special_tokens=True)\n    label_texts = tokenizer.batch_decode(labels, skip_special_tokens=True)\n\n    correct = sum(p.strip().lower() == l.strip().lower() for p, l in zip(pred_texts, label_texts))\n    acc = correct / len(label_texts)\n    print(f\"✅ Accuracy: {acc:.4f}\")\n    return {\"accuracy\": acc}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T12:54:21.687730Z","iopub.execute_input":"2025-05-07T12:54:21.688079Z","iopub.status.idle":"2025-05-07T12:54:21.693743Z","shell.execute_reply.started":"2025-05-07T12:54:21.688039Z","shell.execute_reply":"2025-05-07T12:54:21.692845Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"from transformers import BlipProcessor, BlipForQuestionAnswering, TrainingArguments, Trainer\nimport torch\nfrom torch.utils.data import random_split\nfrom datasets import load_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T12:54:25.048782Z","iopub.execute_input":"2025-05-07T12:54:25.049118Z","iopub.status.idle":"2025-05-07T12:54:25.073067Z","shell.execute_reply.started":"2025-05-07T12:54:25.049086Z","shell.execute_reply":"2025-05-07T12:54:25.072420Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"device=\"cuda\" if torch.cuda.is_available() else \"cpu\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T12:54:28.338422Z","iopub.execute_input":"2025-05-07T12:54:28.339290Z","iopub.status.idle":"2025-05-07T12:54:28.343582Z","shell.execute_reply.started":"2025-05-07T12:54:28.339262Z","shell.execute_reply":"2025-05-07T12:54:28.342503Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"# Training cell \n","metadata":{}},{"cell_type":"code","source":"\ntorch.cuda.empty_cache()  # Clears unused memory from the cache","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import BlipProcessor, BlipForQuestionAnswering\nfrom peft import get_peft_model, LoraConfig, TaskType\nfrom torch.utils.data import DataLoader, random_split\nimport torch\nfrom torch import optim\nimport os\nimport matplotlib.pyplot as plt\nimport json\n\n# ---------- Setup ----------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Load processor and base model\nprocessor = BlipProcessor.from_pretrained(\"Salesforce/blip-vqa-base\")\nmodel = BlipForQuestionAnswering.from_pretrained(\"Salesforce/blip-vqa-base\")\nmodel.to(device)\n\n# Apply LoRA\nlora_config = LoraConfig(\n    r=8,\n    lora_alpha=32,\n    target_modules=['qkv', 'projection'],\n    lora_dropout=0.05,\n    bias='none'\n)\nmodel = get_peft_model(model, lora_config)\nmodel.print_trainable_parameters()\n\n# ---------- Dataset Setup ----------\njson_root_dir = \"/kaggle/input/master-train/master_train/batch_1\"\nimage_base_dir = \"/kaggle/input/abo-dataset\"\ndataset = VQADataset(json_dirs=json_root_dir, base_img_path=image_base_dir, processor=processor)\n\n# Split dataset\nsplit_ratio = 0.9\ntrain_size = int(split_ratio * len(dataset))\neval_size = len(dataset) - train_size\ntrain_dataset, eval_dataset = random_split(dataset, [train_size, eval_size])\n\n# Create DataLoaders\ntrain_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\neval_loader = DataLoader(eval_dataset, batch_size=8)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T12:54:32.133331Z","iopub.execute_input":"2025-05-07T12:54:32.133970Z","iopub.status.idle":"2025-05-07T12:54:50.494736Z","shell.execute_reply.started":"2025-05-07T12:54:32.133947Z","shell.execute_reply":"2025-05-07T12:54:50.493890Z"}},"outputs":[{"name":"stderr","text":"Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n","output_type":"stream"},{"name":"stdout","text":"trainable params: 442,368 || all params: 385,114,940 || trainable%: 0.1149\n📁 Scanning JSON folders: /kaggle/input/master-train/master_train/batch_1\n✅ Loaded 145088 samples.\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"import os\nimport torch\nimport torch.optim as optim\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\n\n# ---------- Optimizer ----------\noptimizer = optim.AdamW(model.parameters(), lr=5e-5)\n\n# Save setup\nsave_path = \"/kaggle/working/model_latest\"\nos.makedirs(save_path, exist_ok=True)\nsave_every = 1000  # save every N steps\n\n# Resume state (optional)\nresume_state_path = os.path.join(save_path, \"training_state.pt\")\nstart_step = 0\nloss_history = []\n\nif os.path.exists(resume_state_path):\n    print(\"🔁 Resuming training from checkpoint...\")\n    checkpoint = torch.load(resume_state_path)\n    model.load_state_dict(checkpoint[\"model_state\"])\n    optimizer.load_state_dict(checkpoint[\"optimizer_state\"])\n    start_step = checkpoint[\"step\"]\n    loss_history = checkpoint[\"loss_history\"]\n\n# ---------- Training Loop ----------\nepochs = 1\nmodel.train()\nstep_counter = start_step\ntotal_steps = len(train_loader) * epochs\n\nfor epoch in range(epochs):\n    print(f\"🔥 Epoch {epoch + 1}\")\n    epoch_bar = tqdm(train_loader, desc=f\"Epoch {epoch + 1}\", leave=False)\n    for batch in epoch_bar:\n        step_counter += 1\n\n        # Move inputs to device\n        inputs = {k: v.to(device) for k, v in batch.items() if isinstance(v, torch.Tensor)}\n\n        # Forward pass\n        outputs = model(**inputs)\n        loss = outputs.loss\n\n        # Backward pass\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        # Log loss\n        loss_history.append((step_counter, loss.item()))\n\n        # Progress update on tqdm bar\n        epoch_bar.set_postfix({\n            \"Step\": step_counter,\n            \"Loss\": f\"{loss.item():.4f}\",\n            \"Progress\": f\"{(step_counter / total_steps) * 100:.2f}%\"\n        })\n\n        # Save every N steps\n        if step_counter % save_every == 0:\n            print(f\"💾 Saving at step {step_counter}...\")\n            model.save_pretrained(save_path)\n            processor.save_pretrained(save_path)\n            torch.save({\n                \"model_state\": model.state_dict(),\n                \"optimizer_state\": optimizer.state_dict(),\n                \"step\": step_counter,\n                \"loss_history\": loss_history,\n            }, resume_state_path)\n\n# Final Save\nprint(\"✅ Final save after training...\")\nmodel.save_pretrained(save_path)\nprocessor.save_pretrained(save_path)\ntorch.save({\n    \"model_state\": model.state_dict(),\n    \"optimizer_state\": optimizer.state_dict(),\n    \"step\": step_counter,\n    \"loss_history\": loss_history,\n}, resume_state_path)\n\n# ---------- Plot Loss ----------\nsteps, losses = zip(*loss_history)\nplt.figure(figsize=(10, 5))\nplt.plot(steps, losses, label=\"Training Loss\")\nplt.xlabel(\"Step\")\nplt.ylabel(\"Loss\")\nplt.title(\"Loss vs. Training Step\")\nplt.grid(True)\nplt.legend()\nplt.savefig(os.path.join(save_path, \"loss_plot.png\"))\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T13:08:00.951205Z","iopub.execute_input":"2025-05-07T13:08:00.952016Z","iopub.status.idle":"2025-05-07T14:12:36.062451Z","shell.execute_reply.started":"2025-05-07T13:08:00.951981Z","shell.execute_reply":"2025-05-07T14:12:36.061243Z"}},"outputs":[{"name":"stdout","text":"🔁 Resuming training from checkpoint...\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_210/634067154.py:22: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  checkpoint = torch.load(resume_state_path)\n","output_type":"stream"},{"name":"stdout","text":"🔥 Epoch 1\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:   6%|▌         | 999/16323 [10:47<2:44:16,  1.55it/s, Step=12000, Loss=8.2186, Progress=73.52%]","output_type":"stream"},{"name":"stdout","text":"💾 Saving at step 12000...\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  12%|█▏        | 1999/16323 [21:39<2:35:09,  1.54it/s, Step=13000, Loss=8.0252, Progress=79.64%]","output_type":"stream"},{"name":"stdout","text":"💾 Saving at step 13000...\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  18%|█▊        | 2999/16323 [32:29<2:22:09,  1.56it/s, Step=14000, Loss=8.4450, Progress=85.77%]","output_type":"stream"},{"name":"stdout","text":"💾 Saving at step 14000...\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  24%|██▍       | 3999/16323 [43:19<2:12:55,  1.55it/s, Step=15000, Loss=8.5735, Progress=91.89%]","output_type":"stream"},{"name":"stdout","text":"💾 Saving at step 15000...\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  31%|███       | 4999/16323 [54:10<2:03:15,  1.53it/s, Step=16000, Loss=8.3617, Progress=98.02%]","output_type":"stream"},{"name":"stdout","text":"💾 Saving at step 16000...\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                            \r","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_210/634067154.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;31m# Log loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mloss_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_counter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;31m# Progress update on tqdm bar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":15},{"cell_type":"markdown","source":"# Batch -2 onwards training","metadata":{}},{"cell_type":"code","source":"# from transformers import BlipProcessor, BlipForQuestionAnswering\n# from peft import get_peft_model, LoraConfig, TaskType\n# from torch.utils.data import DataLoader, random_split\n# import torch\n# from torch import optim\n# import os\n# import matplotlib.pyplot as plt\n\n# # ---------- Setup ----------\n# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# # Paths\n# save_path = \"/kaggle/working/model_latest\"\n# resume_state_path = os.path.join(save_path, \"training_state.pt\")\n\n# # Load processor and base model\n# processor = BlipProcessor.from_pretrained(save_path)\n# model = BlipForQuestionAnswering.from_pretrained(save_path)\n\n# # Apply same LoRA configuration\n# lora_config = LoraConfig(\n#     r=8,\n#     lora_alpha=32,\n#     target_modules=['qkv', 'projection'],\n#     lora_dropout=0.05,\n#     bias='none'\n# )\n# model = get_peft_model(model, lora_config)\n# model.to(device)\n\n# # ---------- Load Optimizer and Training State ----------\n# optimizer = optim.AdamW(model.parameters(), lr=5e-5)\n\n# if os.path.exists(resume_state_path):\n#     print(\"🔁 Loading previous training state...\")\n#     checkpoint = torch.load(resume_state_path)\n#     model.load_state_dict(checkpoint[\"model_state\"])\n#     optimizer.load_state_dict(checkpoint[\"optimizer_state\"])\n#     start_step = checkpoint[\"step\"]\n#     loss_history = checkpoint[\"loss_history\"]\n# else:\n#     print(\"⚠️ No checkpoint found. Starting from scratch.\")\n#     start_step = 0\n#     loss_history = []\n\n# # ---------- Load New Batch Dataset (e.g., batch_2) ----------\n# json_root_dir = \"/kaggle/input/master-train/master_train/batch_2\"  # NEW batch\n# image_base_dir = \"/kaggle/input/abo-dataset\"\n# dataset = VQADataset(json_dirs=json_root_dir, base_img_path=image_base_dir, processor=processor)\n\n# # Split and prepare data\n# split_ratio = 0.9\n# train_size = int(split_ratio * len(dataset))\n# eval_size = len(dataset) - train_size\n# train_dataset, eval_dataset = random_split(dataset, [train_size, eval_size])\n# train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n# eval_loader = DataLoader(eval_dataset, batch_size=4)\n\n# # ---------- Resume Training Loop ----------\n# epochs = 1\n# save_every = 1000\n# model.train()\n# step_counter = start_step\n# total_steps = len(train_loader) * epochs\n\n# for epoch in range(epochs):\n#     print(f\"🔥 Continuing at Epoch {epoch+1}\")\n#     for batch in train_loader:\n#         step_counter += 1\n\n#         # Move inputs to device\n#         inputs = {k: v.to(device) for k, v in batch.items() if isinstance(v, torch.Tensor)}\n\n#         # Forward and Backward pass\n#         outputs = model(**inputs)\n#         loss = outputs.loss\n#         optimizer.zero_grad()\n#         loss.backward()\n#         optimizer.step()\n\n#         # Log loss\n#         loss_history.append((step_counter, loss.item()))\n\n#         # Display progress\n#         progress = (step_counter / total_steps) * 100\n#         print(f\"Step {step_counter}/{total_steps} - Loss: {loss.item():.4f} - ✅ {progress:.2f}%\")\n\n#         # Periodic Save\n#         if step_counter % save_every == 0:\n#             print(\"💾 Saving checkpoint...\")\n#             model.save_pretrained(save_path)\n#             processor.save_pretrained(save_path)\n#             torch.save({\n#                 \"model_state\": model.state_dict(),\n#                 \"optimizer_state\": optimizer.state_dict(),\n#                 \"step\": step_counter,\n#                 \"loss_history\": loss_history\n#             }, resume_state_path)\n\n# # Final save after continued training\n# print(\"✅ Final save after continued training...\")\n# model.save_pretrained(save_path)\n# processor.save_pretrained(save_path)\n# torch.save({\n#     \"model_state\": model.state_dict(),\n#     \"optimizer_state\": optimizer.state_dict(),\n#     \"step\": step_counter,\n#     \"loss_history\": loss_history\n# }, resume_state_path)\n\n# # ---------- Loss Plot ----------\n# steps, losses = zip(*loss_history)\n# plt.figure(figsize=(10, 5))\n# plt.plot(steps, losses, label=\"Training Loss\")\n# plt.xlabel(\"Step\")\n# plt.ylabel(\"Loss\")\n# plt.title(\"Loss vs. Training Step (Continued)\")\n# plt.grid(True)\n# plt.legend()\n# plt.savefig(os.path.join(save_path, \"loss_plot_continued.png\"))\n# plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import shutil\n\n# Compress folder into a zip file\nshutil.make_archive('/kaggle/working/model_latest', 'zip', '/kaggle/working/model_latest')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T14:14:45.680084Z","iopub.execute_input":"2025-05-07T14:14:45.680652Z","iopub.status.idle":"2025-05-07T14:16:14.218684Z","shell.execute_reply.started":"2025-05-07T14:14:45.680627Z","shell.execute_reply":"2025-05-07T14:16:14.217667Z"}},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/model_latest.zip'"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"!pip install bert-score\n!pip install scikit-learn","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T14:22:16.385506Z","iopub.execute_input":"2025-05-07T14:22:16.386497Z","iopub.status.idle":"2025-05-07T14:22:23.762890Z","shell.execute_reply.started":"2025-05-07T14:22:16.386470Z","shell.execute_reply":"2025-05-07T14:22:23.761636Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: bert-score in /usr/local/lib/python3.11/dist-packages (0.3.13)\nRequirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from bert-score) (2.5.1+cu124)\nRequirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from bert-score) (2.2.3)\nRequirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from bert-score) (4.51.1)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from bert-score) (1.26.4)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from bert-score) (2.32.3)\nRequirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.11/dist-packages (from bert-score) (4.67.1)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from bert-score) (3.7.5)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from bert-score) (24.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert-score) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert-score) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert-score) (2025.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->bert-score) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->bert-score) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->bert-score) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->bert-score) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->bert-score) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->bert-score) (2.4.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (4.13.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (2024.12.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.3.1.170)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.4.127)\nRequirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (3.1.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.0.0->bert-score) (1.3.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert-score) (0.30.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert-score) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert-score) (2024.11.6)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert-score) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert-score) (0.5.2)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (4.56.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (1.4.8)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (11.1.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (3.2.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->bert-score) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->bert-score) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->bert-score) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->bert-score) (2025.1.31)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert-score) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.0.0->bert-score) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->bert-score) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->bert-score) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->bert-score) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->bert-score) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->bert-score) (2024.2.0)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.2.2)\nRequirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.26.4)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.2)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.3->scikit-learn) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.3->scikit-learn) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17.3->scikit-learn) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17.3->scikit-learn) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17.3->scikit-learn) (2024.2.0)\n","output_type":"stream"}],"execution_count":24},{"cell_type":"markdown","source":"# Testing cell \n","metadata":{}},{"cell_type":"code","source":"import os\nimport torch\nfrom torch.amp import autocast\nfrom torch.utils.data import DataLoader\nfrom tqdm import tqdm\nfrom transformers import BlipProcessor, BlipForQuestionAnswering\nfrom accelerate import Accelerator\nimport time\nfrom sklearn.metrics import f1_score\nfrom bert_score import score as bert_score_fn\n\n# Step 1: Set environment variable to disable tokenizer parallelism warning\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n\n# Initialize Accelerator\naccelerator = Accelerator()\ndevice = accelerator.device\n\n# Load model and processor\nload_path = \"/kaggle/working/model_latest\"\nmodel = BlipForQuestionAnswering.from_pretrained(load_path)\nprocessor = BlipProcessor.from_pretrained(load_path)\n\n# Prepare model for distributed inference\nmodel = accelerator.prepare(model)\n\n# Load dataset\ntest_json_dir = \"/kaggle/input/master-test/test_dataset\"\ntest_image_dir = \"/kaggle/input/abo-dataset\"\ntest_dataset = VQADataset(\n    json_dirs=test_json_dir,\n    base_img_path=test_image_dir,\n    processor=processor\n)\n\n# DataLoader setup\nbatch_size = 64\nnum_workers = 12\ntest_loader = DataLoader(\n    test_dataset,\n    batch_size=batch_size,\n    shuffle=False,\n    num_workers=num_workers,\n    pin_memory=True,\n    persistent_workers=True\n)\n\n# Evaluation setup\nmodel.eval()\ncorrect = 0\ntotal = 0\nbatch_count = len(test_loader)\n\npredicted_all = []\ntrue_all = []\n\nstart_time = time.time()\n\n# Evaluation loop\nwith torch.no_grad():\n    for batch in tqdm(test_loader, total=batch_count, desc=\"Evaluating\"):\n        pixel_values = batch[\"pixel_values\"].to(device)\n        input_ids = batch[\"input_ids\"].to(device)\n        attention_mask = batch[\"attention_mask\"].to(device)\n        answers = batch[\"labels\"]\n\n        with autocast(device_type=device.type, dtype=torch.float16):\n            generated_ids = model.generate(\n                input_ids=input_ids,\n                pixel_values=pixel_values,\n                attention_mask=attention_mask,\n                max_length=20,\n                do_sample=False,\n                num_beams=1\n            )\n\n        predicted_answers = processor.batch_decode(generated_ids, skip_special_tokens=True)\n        decoded_answers = [\n            processor.tokenizer.decode(ans, skip_special_tokens=True)\n            if isinstance(ans, torch.Tensor) else ans\n            for ans in answers\n        ]\n\n        for pred, true_ans_str in zip(predicted_answers, decoded_answers):\n            pred_clean = pred.strip().lower()\n            true_clean = true_ans_str.strip().lower()\n\n            predicted_all.append(pred_clean)\n            true_all.append(true_clean)\n\n            if pred_clean == true_clean:\n                correct += 1\n            total += 1\n\nend_time = time.time()\nelapsed = end_time - start_time\n\n# Compute Exact Match\nexact_match = 100 * correct / total\n\n# Compute Token-level F1 Score (macro)\ntoken_f1 = f1_score(\n    [ans.split() for ans in true_all],\n    [pred.split() for pred in predicted_all],\n    average='macro'\n)\n\n# Compute BERTScore\nP, R, F1 = bert_score_fn(predicted_all, true_all, lang=\"en\", verbose=True)\nbert_score_f1 = F1.mean().item()\nbert_score_precision = P.mean().item()\nbert_score_recall = R.mean().item()\n\n# Print all metrics\nprint(f\"\\n📊 Evaluation Metrics:\")\nprint(f\"✅ Exact Match (EM): {exact_match:.2f}%\")\nprint(f\"🔤 F1 Score (token-level): {token_f1:.4f}\")\nprint(f\"🤖 BERTScore - Precision: {bert_score_precision:.4f}\")\nprint(f\"🤖 BERTScore - Recall:    {bert_score_recall:.4f}\")\nprint(f\"🤖 BERTScore - F1:        {bert_score_f1:.4f}\")\nprint(f\"\\n⏱️ Total Evaluation Time: {elapsed:.2f} seconds for {total} samples.\")\nprint(f\"⚡ Inference Speed: {total / elapsed:.2f} it/sec\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T14:27:12.798413Z","iopub.execute_input":"2025-05-07T14:27:12.799126Z","iopub.status.idle":"2025-05-07T18:47:11.391432Z","shell.execute_reply.started":"2025-05-07T14:27:12.799101Z","shell.execute_reply":"2025-05-07T18:47:11.389423Z"}},"outputs":[{"name":"stdout","text":"📁 Scanning JSON folders: /kaggle/input/master-test/test_dataset\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"✅ Loaded 482036 samples.\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|██████████| 7532/7532 [4:16:50<00:00,  2.05s/it]  \n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_210/1726838141.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;31m# Compute Token-level F1 Score (macro)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m token_f1 = f1_score(\n\u001b[0m\u001b[1;32m    103\u001b[0m     \u001b[0;34m[\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mans\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrue_all\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;34m[\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpredicted_all\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mf1_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.66666667\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m        \u001b[0;34m,\u001b[0m \u001b[0;36m0.66666667\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m     \"\"\"\n\u001b[0;32m-> 1146\u001b[0;31m     return fbeta_score(\n\u001b[0m\u001b[1;32m   1147\u001b[0m         \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1285\u001b[0m     \"\"\"\n\u001b[1;32m   1286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1287\u001b[0;31m     _, _, f, _ = precision_recall_fscore_support(\n\u001b[0m\u001b[1;32m   1288\u001b[0m         \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1289\u001b[0m         \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1571\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbeta\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1572\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1573\u001b[0;31m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_set_wise_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1575\u001b[0m     \u001b[0;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1372\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"average has to be one of \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maverage_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1374\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1375\u001b[0m     \u001b[0;31m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1376\u001b[0m     \u001b[0;31m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     85\u001b[0m     \"\"\"\n\u001b[1;32m     86\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y_true\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y_pred\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36mtype_of_target\u001b[0;34m(y, input_name)\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m         ):\n\u001b[0;32m--> 345\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    346\u001b[0m                 \u001b[0;34m\"You appear to be using a legacy multi-label data\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m                 \u001b[0;34m\" representation. Sequence of sequences are no\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: You appear to be using a legacy multi-label data representation. Sequence of sequences are no longer supported; use a binary array or sparse matrix instead - the MultiLabelBinarizer transformer can convert to this format."],"ename":"ValueError","evalue":"You appear to be using a legacy multi-label data representation. Sequence of sequences are no longer supported; use a binary array or sparse matrix instead - the MultiLabelBinarizer transformer can convert to this format.","output_type":"error"}],"execution_count":27},{"cell_type":"code","source":"print(f\"✅ Exact Match (EM): {exact_match:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T18:49:19.545063Z","iopub.execute_input":"2025-05-07T18:49:19.546033Z","iopub.status.idle":"2025-05-07T18:49:19.551403Z","shell.execute_reply.started":"2025-05-07T18:49:19.545985Z","shell.execute_reply":"2025-05-07T18:49:19.550746Z"}},"outputs":[{"name":"stdout","text":"✅ Exact Match (EM): 18.41%\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"from bert_score import score as bert_score_fn\n\nP, R, F1 = bert_score_fn(predicted_all, true_all, lang=\"en\", verbose=True)\nbert_score_precision = P.mean().item()\nbert_score_recall = R.mean().item()\nbert_score_f1 = F1.mean().item()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T18:57:50.016058Z","iopub.execute_input":"2025-05-07T18:57:50.016819Z","iopub.status.idle":"2025-05-07T18:59:46.032054Z","shell.execute_reply.started":"2025-05-07T18:57:50.016783Z","shell.execute_reply":"2025-05-07T18:59:46.031330Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a0182c0c48b41d483e0e77d0e3c23eb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"349376a5050e414cbb41fd346064158e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c5baa634e34a4af1b10ebc9b53e16068"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e0bab8e199dd45d39f4b577c3c3efaa9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c6e4a4e375114e3a9657ec2fc88ad14c"}},"metadata":{}},{"name":"stderr","text":"Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a4ca4ae672a47619c79c46d84935247"}},"metadata":{}},{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"calculating scores...\ncomputing bert embedding.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/436 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"701cb2c4ab3d468494615715bc8f67e5"}},"metadata":{}},{"name":"stdout","text":"computing greedy matching.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/7532 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e9e5617761f04d4d85f339175761fe9c"}},"metadata":{}},{"name":"stderr","text":"Warning: Empty reference sentence detected; setting raw BERTScores to 0.\nWarning: Empty reference sentence detected; setting raw BERTScores to 0.\nWarning: Empty reference sentence detected; setting raw BERTScores to 0.\nWarning: Empty reference sentence detected; setting raw BERTScores to 0.\nWarning: Empty reference sentence detected; setting raw BERTScores to 0.\nWarning: Empty reference sentence detected; setting raw BERTScores to 0.\nWarning: Empty reference sentence detected; setting raw BERTScores to 0.\nWarning: Empty reference sentence detected; setting raw BERTScores to 0.\nWarning: Empty reference sentence detected; setting raw BERTScores to 0.\nWarning: Empty reference sentence detected; setting raw BERTScores to 0.\nWarning: Empty reference sentence detected; setting raw BERTScores to 0.\nWarning: Empty reference sentence detected; setting raw BERTScores to 0.\nWarning: Empty reference sentence detected; setting raw BERTScores to 0.\nWarning: Empty reference sentence detected; setting raw BERTScores to 0.\nWarning: Empty reference sentence detected; setting raw BERTScores to 0.\nWarning: Empty reference sentence detected; setting raw BERTScores to 0.\nWarning: Empty reference sentence detected; setting raw BERTScores to 0.\nWarning: Empty reference sentence detected; setting raw BERTScores to 0.\nWarning: Empty reference sentence detected; setting raw BERTScores to 0.\nWarning: Empty reference sentence detected; setting raw BERTScores to 0.\nWarning: Empty reference sentence detected; setting raw BERTScores to 0.\n","output_type":"stream"},{"name":"stdout","text":"done in 104.26 seconds, 4623.57 sentences/sec\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"print(f\"🤖 BERTScore - Precision: {bert_score_precision:.4f}\")\nprint(f\"🤖 BERTScore - Recall:    {bert_score_recall:.4f}\")\nprint(f\"🤖 BERTScore - F1:        {bert_score_f1:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T19:00:16.623053Z","iopub.execute_input":"2025-05-07T19:00:16.623737Z","iopub.status.idle":"2025-05-07T19:00:16.627861Z","shell.execute_reply.started":"2025-05-07T19:00:16.623715Z","shell.execute_reply":"2025-05-07T19:00:16.627205Z"}},"outputs":[{"name":"stdout","text":"🤖 BERTScore - Precision: 0.9573\n🤖 BERTScore - Recall:    0.9352\n🤖 BERTScore - F1:        0.9452\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"print(f\"\\n⏱️ Total Evaluation Time: {elapsed:.2f} seconds for {total} samples.\")\nprint(f\"⚡ Inference Speed: {total / elapsed:.2f} it/sec\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T18:52:49.238788Z","iopub.execute_input":"2025-05-07T18:52:49.239131Z","iopub.status.idle":"2025-05-07T18:52:49.244201Z","shell.execute_reply.started":"2025-05-07T18:52:49.239108Z","shell.execute_reply":"2025-05-07T18:52:49.243156Z"}},"outputs":[{"name":"stdout","text":"\n⏱️ Total Evaluation Time: 15410.73 seconds for 482036 samples.\n⚡ Inference Speed: 31.28 it/sec\n","output_type":"stream"}],"execution_count":33}]}