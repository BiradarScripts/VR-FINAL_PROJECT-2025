{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11629593,"sourceType":"datasetVersion","datasetId":7296443},{"sourceId":11645228,"sourceType":"datasetVersion","datasetId":7307471},{"sourceId":11676506,"sourceType":"datasetVersion","datasetId":7328450},{"sourceId":11676725,"sourceType":"datasetVersion","datasetId":7328608},{"sourceId":11735199,"sourceType":"datasetVersion","datasetId":7359196}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers datasets peft torch accelerate pillow bitsandbytes # bitsandbytes often needed for efficient loading","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T15:54:21.978206Z","iopub.execute_input":"2025-05-08T15:54:21.978380Z","iopub.status.idle":"2025-05-08T15:55:47.103688Z","shell.execute_reply.started":"2025-05-08T15:54:21.978365Z","shell.execute_reply":"2025-05-08T15:55:47.102771Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.1)\nRequirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.0)\nRequirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.14.0)\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\nRequirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.3.0)\nRequirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.1.0)\nCollecting bitsandbytes\n  Downloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.3)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\nCollecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets)\n  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.16)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft) (7.0.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.2.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.19.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m72.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, fsspec, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, bitsandbytes\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.8.93\n    Uninstalling nvidia-nvjitlink-cu12-12.8.93:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.93\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.9.90\n    Uninstalling nvidia-curand-cu12-10.3.9.90:\n      Successfully uninstalled nvidia-curand-cu12-10.3.9.90\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.3.3.83\n    Uninstalling nvidia-cufft-cu12-11.3.3.83:\n      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.8.4.1\n    Uninstalling nvidia-cublas-cu12-12.8.4.1:\n      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2025.3.2\n    Uninstalling fsspec-2025.3.2:\n      Successfully uninstalled fsspec-2025.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.8.93\n    Uninstalling nvidia-cusparse-cu12-12.5.8.93:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.3.90\n    Uninstalling nvidia-cusolver-cu12-11.7.3.90:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.12.0 which is incompatible.\nbigframes 1.36.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed bitsandbytes-0.45.5 fsspec-2024.12.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport json\nimport torch\nfrom PIL import Image\nfrom torch.utils.data import Dataset, DataLoader, random_split\nfrom transformers import Blip2ForConditionalGeneration, Blip2Processor, TrainingArguments, Trainer\nfrom peft import get_peft_model, LoraConfig, TaskType","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T15:55:47.107354Z","iopub.execute_input":"2025-05-08T15:55:47.107519Z","iopub.status.idle":"2025-05-08T15:56:16.110941Z","shell.execute_reply.started":"2025-05-08T15:55:47.107502Z","shell.execute_reply":"2025-05-08T15:56:16.110351Z"}},"outputs":[{"name":"stderr","text":"2025-05-08 15:56:00.609982: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1746719760.894814      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1746719760.968914      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"class VQADataset(Dataset):\n    def __init__(self, json_dirs, base_img_path, processor):\n        self.samples = []\n        self.processor = processor\n        self.base_img_path = base_img_path\n\n        print(f\"📁 Scanning JSON folders: {json_dirs}\")\n\n        for dir_path in ([json_dirs] if isinstance(json_dirs, str) else json_dirs):\n            for root, _, files in os.walk(dir_path):\n                for file in files:\n                    if file.endswith(\".json\"):\n                        json_path = os.path.join(root, file)\n                        with open(json_path, \"r\") as f:\n                            data = json.load(f)\n\n                        image_rel_path = data[\"image_path\"].replace(\"\\\\\", \"/\")\n\n                        # Remove everything before and including 'abo-images-small/'\n                        if \"abo-images-small/\" in image_rel_path:\n                            image_rel_path = image_rel_path.split(\"abo-images-small/\", 1)[1]\n\n                        image_path = os.path.join(base_img_path, image_rel_path)\n\n                        for qa in data[\"qa_pairs\"]:\n                            self.samples.append({\n                                \"image_path\": image_path,\n                                \"question\": qa[\"question\"],\n                                \"answer\": qa[\"answer\"]\n                            })\n\n        print(f\"✅ Loaded {len(self.samples)} samples.\")\n\n    def __len__(self):\n        return len(self.samples)\n\n    def __getitem__(self, idx):\n        sample = self.samples[idx]\n        image = Image.open(sample[\"image_path\"]).convert(\"RGB\")\n\n        inputs = self.processor(\n            images=image,\n            text=sample[\"question\"],\n            return_tensors=\"pt\",\n            padding=\"max_length\",\n            truncation=True,\n            max_length=128\n        )\n\n        labels = self.processor.tokenizer(\n            sample[\"answer\"],\n            return_tensors=\"pt\",\n            padding=\"max_length\",\n            truncation=True,\n            max_length=10\n        ).input_ids\n\n        inputs = {k: v.squeeze(0) for k, v in inputs.items()}\n        inputs[\"labels\"] = labels.squeeze(0)\n\n        # Remove inputs_embeds if it exists\n        if \"inputs_embeds\" in inputs:\n            del inputs[\"inputs_embeds\"]\n\n        return inputs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T15:56:16.111632Z","iopub.execute_input":"2025-05-08T15:56:16.112205Z","iopub.status.idle":"2025-05-08T15:56:16.120786Z","shell.execute_reply.started":"2025-05-08T15:56:16.112176Z","shell.execute_reply":"2025-05-08T15:56:16.120059Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"def compute_metrics(pred):\n    preds = pred.predictions\n    labels = pred.label_ids\n\n    tokenizer = Blip2Processor.from_pretrained(\"Salesforce/blip-vqa-base\").tokenizer\n    pred_texts = tokenizer.batch_decode(preds, skip_special_tokens=True)\n    label_texts = tokenizer.batch_decode(labels, skip_special_tokens=True)\n\n    correct = sum(p.strip().lower() == l.strip().lower() for p, l in zip(pred_texts, label_texts))\n    acc = correct / len(label_texts)\n    print(f\"✅ Accuracy: {acc:.4f}\")\n    return {\"accuracy\": acc}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T15:56:16.121543Z","iopub.execute_input":"2025-05-08T15:56:16.121885Z","iopub.status.idle":"2025-05-08T15:56:16.155559Z","shell.execute_reply.started":"2025-05-08T15:56:16.121863Z","shell.execute_reply":"2025-05-08T15:56:16.154862Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"from transformers import BlipProcessor, BlipForQuestionAnswering, TrainingArguments, Trainer\nimport torch\nfrom torch.utils.data import random_split\nfrom datasets import load_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T15:56:16.157236Z","iopub.execute_input":"2025-05-08T15:56:16.157409Z","iopub.status.idle":"2025-05-08T15:56:16.199731Z","shell.execute_reply.started":"2025-05-08T15:56:16.157396Z","shell.execute_reply":"2025-05-08T15:56:16.199258Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"device=\"cuda\" if torch.cuda.is_available() else \"cpu\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T15:56:16.200274Z","iopub.execute_input":"2025-05-08T15:56:16.200464Z","iopub.status.idle":"2025-05-08T15:56:16.204064Z","shell.execute_reply.started":"2025-05-08T15:56:16.200449Z","shell.execute_reply":"2025-05-08T15:56:16.203441Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"# Training cell \n","metadata":{}},{"cell_type":"code","source":"\ntorch.cuda.empty_cache()  # Clears unused memory from the cache","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T20:52:52.023922Z","iopub.execute_input":"2025-05-07T20:52:52.024851Z","iopub.status.idle":"2025-05-07T20:52:52.028534Z","shell.execute_reply.started":"2025-05-07T20:52:52.02481Z","shell.execute_reply":"2025-05-07T20:52:52.027766Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# from transformers import BlipProcessor, BlipForQuestionAnswering\n# from peft import get_peft_model, LoraConfig, TaskType\n# from torch.utils.data import DataLoader, random_split\n# import torch\n# from torch import optim\n# import os\n# import matplotlib.pyplot as plt\n# import json\n\n# # ---------- Setup ----------\n# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# # Load processor and base model\n# processor = BlipProcessor.from_pretrained(\"Salesforce/blip-vqa-base\")\n# model = BlipForQuestionAnswering.from_pretrained(\"Salesforce/blip-vqa-base\")\n# model.to(device)\n\n# # Apply LoRA\n# lora_config = LoraConfig(\n#     r=8,\n#     lora_alpha=32,\n#     target_modules=['qkv', 'projection'],\n#     lora_dropout=0.05,\n#     bias='none'\n# )\n# model = get_peft_model(model, lora_config)\n# model.print_trainable_parameters()\n\n# # ---------- Dataset Setup ----------\n# json_root_dir = \"/kaggle/input/master-train/master_train/batch_1\"\n# image_base_dir = \"/kaggle/input/abo-dataset\"\n# dataset = VQADataset(json_dirs=json_root_dir, base_img_path=image_base_dir, processor=processor)\n\n# # Split dataset\n# split_ratio = 0.9\n# train_size = int(split_ratio * len(dataset))\n# eval_size = len(dataset) - train_size\n# train_dataset, eval_dataset = random_split(dataset, [train_size, eval_size])\n\n# # Create DataLoaders\n# train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n# eval_loader = DataLoader(eval_dataset, batch_size=8)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T12:54:32.133331Z","iopub.execute_input":"2025-05-07T12:54:32.13397Z","iopub.status.idle":"2025-05-07T12:54:50.494736Z","shell.execute_reply.started":"2025-05-07T12:54:32.133947Z","shell.execute_reply":"2025-05-07T12:54:50.49389Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import os\n# import torch\n# import torch.optim as optim\n# import matplotlib.pyplot as plt\n# from tqdm import tqdm\n\n# # ---------- Optimizer ----------\n# optimizer = optim.AdamW(model.parameters(), lr=5e-5)\n\n# # Save setup\n# save_path = \"/kaggle/working/model_latest\"\n# os.makedirs(save_path, exist_ok=True)\n# save_every = 1000  # save every N steps\n\n# # Resume state (optional)\n# resume_state_path = os.path.join(save_path, \"training_state.pt\")\n# start_step = 0\n# loss_history = []\n\n# if os.path.exists(resume_state_path):\n#     print(\"🔁 Resuming training from checkpoint...\")\n#     checkpoint = torch.load(resume_state_path)\n#     model.load_state_dict(checkpoint[\"model_state\"])\n#     optimizer.load_state_dict(checkpoint[\"optimizer_state\"])\n#     start_step = checkpoint[\"step\"]\n#     loss_history = checkpoint[\"loss_history\"]\n\n# # ---------- Training Loop ----------\n# epochs = 1\n# model.train()\n# step_counter = start_step\n# total_steps = len(train_loader) * epochs\n\n# for epoch in range(epochs):\n#     print(f\"🔥 Epoch {epoch + 1}\")\n#     epoch_bar = tqdm(train_loader, desc=f\"Epoch {epoch + 1}\", leave=False)\n#     for batch in epoch_bar:\n#         step_counter += 1\n\n#         # Move inputs to device\n#         inputs = {k: v.to(device) for k, v in batch.items() if isinstance(v, torch.Tensor)}\n\n#         # Forward pass\n#         outputs = model(**inputs)\n#         loss = outputs.loss\n\n#         # Backward pass\n#         optimizer.zero_grad()\n#         loss.backward()\n#         optimizer.step()\n\n#         # Log loss\n#         loss_history.append((step_counter, loss.item()))\n\n#         # Progress update on tqdm bar\n#         epoch_bar.set_postfix({\n#             \"Step\": step_counter,\n#             \"Loss\": f\"{loss.item():.4f}\",\n#             \"Progress\": f\"{(step_counter / total_steps) * 100:.2f}%\"\n#         })\n\n#         # Save every N steps\n#         if step_counter % save_every == 0:\n#             print(f\"💾 Saving at step {step_counter}...\")\n#             model.save_pretrained(save_path)\n#             processor.save_pretrained(save_path)\n#             torch.save({\n#                 \"model_state\": model.state_dict(),\n#                 \"optimizer_state\": optimizer.state_dict(),\n#                 \"step\": step_counter,\n#                 \"loss_history\": loss_history,\n#             }, resume_state_path)\n\n# # Final Save\n# print(\"✅ Final save after training...\")\n# model.save_pretrained(save_path)\n# processor.save_pretrained(save_path)\n# torch.save({\n#     \"model_state\": model.state_dict(),\n#     \"optimizer_state\": optimizer.state_dict(),\n#     \"step\": step_counter,\n#     \"loss_history\": loss_history,\n# }, resume_state_path)\n\n# # ---------- Plot Loss ----------\n# steps, losses = zip(*loss_history)\n# plt.figure(figsize=(10, 5))\n# plt.plot(steps, losses, label=\"Training Loss\")\n# plt.xlabel(\"Step\")\n# plt.ylabel(\"Loss\")\n# plt.title(\"Loss vs. Training Step\")\n# plt.grid(True)\n# plt.legend()\n# plt.savefig(os.path.join(save_path, \"loss_plot.png\"))\n# plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T13:08:00.951205Z","iopub.execute_input":"2025-05-07T13:08:00.952016Z","iopub.status.idle":"2025-05-07T14:12:36.062451Z","shell.execute_reply.started":"2025-05-07T13:08:00.951981Z","shell.execute_reply":"2025-05-07T14:12:36.061243Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Batch -2 onwards training","metadata":{}},{"cell_type":"code","source":"from transformers import BlipProcessor, BlipForQuestionAnswering\nfrom peft import get_peft_model, LoraConfig, TaskType\nfrom torch.utils.data import DataLoader, random_split\nimport torch\nfrom torch import optim\nimport os\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nfrom scipy.ndimage import gaussian_filter1d\n\n# ---------- Setup ----------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# Paths\nload_path = \"/kaggle/input/blip-finetunedmodel-versions/model_latest_4\" # Load from\nsave_path = \"/kaggle/working/model_latest_v5\"                # Save to\nresume_state_path = os.path.join(save_path, \"training_state.pt\")\n\n# Load processor and model from load_path\nprocessor = BlipProcessor.from_pretrained(load_path)\nmodel = BlipForQuestionAnswering.from_pretrained(load_path)\n\n# Apply LoRA configuration\nlora_config = LoraConfig(\n    r=8,\n    lora_alpha=32,\n    target_modules=['qkv', 'projection'],\n    lora_dropout=0.05,\n    bias='none'\n)\nmodel = get_peft_model(model, lora_config)\nmodel.to(device)\n\n# Optimizer\noptimizer = optim.AdamW(model.parameters(), lr=10e-5)\n\n# Load checkpoint if available\nif os.path.exists(resume_state_path):\n    print(\"🔁 Loading checkpoint...\")\n    checkpoint = torch.load(resume_state_path)\n    model.load_state_dict(checkpoint[\"model_state\"])\n    optimizer.load_state_dict(checkpoint[\"optimizer_state\"])\n    start_step = checkpoint[\"step\"]\n    loss_history = checkpoint[\"loss_history\"]\nelse:\n    print(\"🆕 Starting fresh training.\")\n    start_step = 0\n    loss_history = []\n\n# ---------- Dataset ----------\njson_root_dir = \"/kaggle/input/master-train/master_train/batch_5\"\nimage_base_dir = \"/kaggle/input/abo-dataset\"\ndataset = VQADataset(json_dirs=json_root_dir, base_img_path=image_base_dir, processor=processor)\n\n# Split dataset\nsplit_ratio = 0.9\ntrain_size = int(split_ratio * len(dataset))\neval_size = len(dataset) - train_size\ntrain_dataset, eval_dataset = random_split(dataset, [train_size, eval_size])\ntrain_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\neval_loader = DataLoader(eval_dataset, batch_size=8)\n\n# ---------- Training ----------\nepochs = 1\nsave_every = 1000\nstep_counter = start_step\ntotal_steps = len(train_loader) * epochs\nmodel.train()\n\nfor epoch in range(epochs):\n    print(f\"\\n🔥 Epoch {epoch + 1}/{epochs}\")\n    pbar = tqdm(train_loader, total=len(train_loader), desc=f\"Training\")\n    for batch in pbar:\n        step_counter += 1\n\n        inputs = {k: v.to(device) for k, v in batch.items() if isinstance(v, torch.Tensor)}\n        outputs = model(**inputs)\n        loss = outputs.loss\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        loss_history.append((step_counter, loss.item()))\n\n        pbar.set_postfix({\"Step\": step_counter, \"Loss\": f\"{loss.item():.4f}\"})\n\n        # Periodic checkpoint saving\n        if step_counter % save_every == 0:\n            os.makedirs(save_path, exist_ok=True)\n            model.save_pretrained(save_path)\n            processor.save_pretrained(save_path)\n            torch.save({\n                \"model_state\": model.state_dict(),\n                \"optimizer_state\": optimizer.state_dict(),\n                \"step\": step_counter,\n                \"loss_history\": loss_history\n            }, resume_state_path)\n\n# ---------- Final Save ----------\nprint(\"✅ Final save after training.\")\nos.makedirs(save_path, exist_ok=True)\nmodel.save_pretrained(save_path)\nprocessor.save_pretrained(save_path)\ntorch.save({\n    \"model_state\": model.state_dict(),\n    \"optimizer_state\": optimizer.state_dict(),\n    \"step\": step_counter,\n    \"loss_history\": loss_history\n}, resume_state_path)\n\n# ---------- Loss Plot ----------\nsteps, losses = zip(*loss_history)\n# Extract model name from save_path\nmodel_name = os.path.basename(save_path)\n\n# Plot 1: Raw Loss\nplt.figure(figsize=(10, 5))\nplt.plot(steps, losses, label=\"Training Loss\")\nplt.xlabel(\"Step\")\nplt.ylabel(\"Loss\")\nplt.title(f\"{model_name} - Training Loss vs. Steps\")\nplt.grid(True)\nplt.legend()\nplt.savefig(os.path.join(save_path, \"loss_plot_raw.png\"))\nplt.show()\n\n# Plot 2: Smoothed Loss\nsmoothed_losses = gaussian_filter1d(losses, sigma=5)\nplt.figure(figsize=(10, 5))\nplt.plot(steps, smoothed_losses, label=\"Smoothed Training Loss\", color='orange')\nplt.xlabel(\"Step\")\nplt.ylabel(\"Loss\")\nplt.title(f\"{model_name} - Smoothed Loss vs. Steps\")\nplt.grid(True)\nplt.legend()\nplt.savefig(os.path.join(save_path, \"loss_plot_smoothed.png\"))\nplt.show()\n\n# Plot 3: Log-Scale Loss\nplt.figure(figsize=(10, 5))\nplt.semilogy(steps, losses, label=\"Log-Scale Training Loss\", color='green')\nplt.xlabel(\"Step\")\nplt.ylabel(\"Loss (log scale)\")\nplt.title(f\"{model_name} - Log-Scale Loss vs. Steps\")\nplt.grid(True, which='both')\nplt.legend()\nplt.savefig(os.path.join(save_path, \"loss_plot_logscale.png\"))\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T19:58:51.098909Z","iopub.execute_input":"2025-05-08T19:58:51.099245Z","iopub.status.idle":"2025-05-08T19:58:51.182209Z","shell.execute_reply.started":"2025-05-08T19:58:51.099221Z","shell.execute_reply":"2025-05-08T19:58:51.181154Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mHFValidationError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_files\u001b[0;34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0;31m# This is slightly better for only 1 file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m             hf_hub_download(\n\u001b[0m\u001b[1;32m    425\u001b[0m                 \u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0marg_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"repo_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"from_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"to_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m                 \u001b[0mvalidate_repo_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36mvalidate_repo_id\u001b[0;34m(repo_id)\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrepo_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         raise HFValidationError(\n\u001b[0m\u001b[1;32m    155\u001b[0m             \u001b[0;34m\"Repo id must be in the form 'repo_name' or 'namespace/repo_name':\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mHFValidationError\u001b[0m: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/kaggle/input/blip-finetunedmodel-versions/model_latest_v5'. Use `repo_type` argument if needed.","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mHFValidationError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/image_processing_base.py\u001b[0m in \u001b[0;36mget_image_processor_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    339\u001b[0m                 \u001b[0;31m# Load from local folder or from cache or download from model Hub and cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m                 resolved_image_processor_file = cached_file(\n\u001b[0m\u001b[1;32m    341\u001b[0m                     \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, **kwargs)\u001b[0m\n\u001b[1;32m    265\u001b[0m     \"\"\"\n\u001b[0;32m--> 266\u001b[0;31m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcached_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_files\u001b[0;34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[0;31m# Now we try to recover if we can find all files correctly in the cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 470\u001b[0;31m         resolved_files = [\n\u001b[0m\u001b[1;32m    471\u001b[0m             \u001b[0m_get_cache_file_to_return\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrevision\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfull_filenames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    470\u001b[0m         resolved_files = [\n\u001b[0;32m--> 471\u001b[0;31m             \u001b[0m_get_cache_file_to_return\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrevision\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfull_filenames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m         ]\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36m_get_cache_file_to_return\u001b[0;34m(path_or_repo_id, full_filename, cache_dir, revision)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;31m# We try to see if we have a cached version (not up to date):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     \u001b[0mresolved_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtry_to_load_from_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrevision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrevision\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresolved_file\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mresolved_file\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0m_CACHED_NO_EXIST\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0marg_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"repo_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"from_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"to_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m                 \u001b[0mvalidate_repo_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36mvalidate_repo_id\u001b[0;34m(repo_id)\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrepo_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         raise HFValidationError(\n\u001b[0m\u001b[1;32m    155\u001b[0m             \u001b[0;34m\"Repo id must be in the form 'repo_name' or 'namespace/repo_name':\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mHFValidationError\u001b[0m: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/kaggle/input/blip-finetunedmodel-versions/model_latest_v5'. Use `repo_type` argument if needed.","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_31/478773348.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Load processor and model from load_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mprocessor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBlipProcessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBlipForQuestionAnswering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/processing_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, **kwargs)\u001b[0m\n\u001b[1;32m   1077\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"token\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1079\u001b[0;31m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_arguments_from_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1080\u001b[0m         \u001b[0mprocessor_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_processor_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m         \u001b[0mprocessor_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprocessor_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/processing_utils.py\u001b[0m in \u001b[0;36m_get_arguments_from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m   1141\u001b[0m                 \u001b[0mattribute_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_possibly_dynamic_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1143\u001b[0;31m             \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattribute_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1144\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/image_processing_base.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, **kwargs)\u001b[0m\n\u001b[1;32m    206\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"token\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mimage_processor_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_image_processor_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_processor_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/image_processing_base.py\u001b[0m in \u001b[0;36mget_image_processor_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m                 \u001b[0;31m# For any other exception, we throw a generic error.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m                 raise OSError(\n\u001b[0m\u001b[1;32m    360\u001b[0m                     \u001b[0;34mf\"Can't load image processor for '{pretrained_model_name_or_path}'. If you were trying to load\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m                     \u001b[0;34m\" it from 'https://huggingface.co/models', make sure you don't have a local directory with the\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOSError\u001b[0m: Can't load image processor for '/kaggle/input/blip-finetunedmodel-versions/model_latest_v5'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/kaggle/input/blip-finetunedmodel-versions/model_latest_v5' is the correct path to a directory containing a preprocessor_config.json file"],"ename":"OSError","evalue":"Can't load image processor for '/kaggle/input/blip-finetunedmodel-versions/model_latest_v5'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '/kaggle/input/blip-finetunedmodel-versions/model_latest_v5' is the correct path to a directory containing a preprocessor_config.json file","output_type":"error"}],"execution_count":13},{"cell_type":"code","source":"# ---------- Final Save ----------\nprint(\"✅ Final save after training.\")\nos.makedirs(save_path, exist_ok=True)\nmodel.save_pretrained(save_path)\nprocessor.save_pretrained(save_path)\ntorch.save({\n    \"model_state\": model.state_dict(),\n    \"optimizer_state\": optimizer.state_dict(),\n    \"step\": step_counter,\n    \"loss_history\": loss_history\n}, resume_state_path)\n\n# ---------- Loss Plot ----------\nsteps, losses = zip(*loss_history)\nplt.figure(figsize=(10, 5))\nplt.plot(steps, losses, label=\"Training Loss\")\nplt.xlabel(\"Step\")\nplt.ylabel(\"Loss\")\nplt.title(\"Loss vs. Training Step (Continued)\")\nplt.grid(True)\nplt.legend()\nplt.savefig(os.path.join(save_path, \"loss_plot_continued.png\"))\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T14:40:07.714437Z","iopub.execute_input":"2025-05-08T14:40:07.714924Z","iopub.status.idle":"2025-05-08T14:40:12.555993Z","shell.execute_reply.started":"2025-05-08T14:40:07.714899Z","shell.execute_reply":"2025-05-08T14:40:12.555207Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import os\n\n# zip_path = '/kaggle/working/your_file.zip'  # Replace with your actual ZIP filename\n\n# if os.path.exists(zip_path):\n#     os.remove(zip_path)\n#     print(f\"Deleted: {zip_path}\")\n# else:\n#     print(f\"File not found: {zip_path}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import shutil\n\n# Compress folder into a zip file\nshutil.make_archive('/kaggle/working/model_latest_v4', 'zip', '/kaggle/working/model_latest_v4')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T14:42:17.693886Z","iopub.execute_input":"2025-05-08T14:42:17.694504Z","iopub.status.idle":"2025-05-08T14:43:33.797442Z","shell.execute_reply.started":"2025-05-08T14:42:17.694479Z","shell.execute_reply":"2025-05-08T14:43:33.796746Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"torch.cuda.empty_cache()  # Clears unused memory from the cache","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T14:47:07.182946Z","iopub.execute_input":"2025-05-08T14:47:07.18377Z","iopub.status.idle":"2025-05-08T14:47:07.286989Z","shell.execute_reply.started":"2025-05-08T14:47:07.183738Z","shell.execute_reply":"2025-05-08T14:47:07.28614Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install bert-score\n!pip install scikit-learn","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T15:56:16.204775Z","iopub.execute_input":"2025-05-08T15:56:16.205019Z","iopub.status.idle":"2025-05-08T15:56:22.800207Z","shell.execute_reply.started":"2025-05-08T15:56:16.205003Z","shell.execute_reply":"2025-05-08T15:56:22.799204Z"}},"outputs":[{"name":"stdout","text":"Collecting bert-score\n  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\nRequirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from bert-score) (2.5.1+cu124)\nRequirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from bert-score) (2.2.3)\nRequirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from bert-score) (4.51.1)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from bert-score) (1.26.4)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from bert-score) (2.32.3)\nRequirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.11/dist-packages (from bert-score) (4.67.1)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from bert-score) (3.7.5)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from bert-score) (24.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert-score) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert-score) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert-score) (2025.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->bert-score) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->bert-score) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->bert-score) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->bert-score) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->bert-score) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->bert-score) (2.4.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (4.13.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (2024.12.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.3.1.170)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.4.127)\nRequirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (3.1.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.0.0->bert-score) (1.3.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert-score) (0.30.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert-score) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert-score) (2024.11.6)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert-score) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert-score) (0.5.2)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (4.56.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (1.4.8)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (11.1.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (3.2.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->bert-score) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->bert-score) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->bert-score) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->bert-score) (2025.1.31)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert-score) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.0.0->bert-score) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->bert-score) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->bert-score) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->bert-score) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->bert-score) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->bert-score) (2024.2.0)\nDownloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: bert-score\nSuccessfully installed bert-score-0.3.13\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.2.2)\nRequirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.26.4)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.2)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.3->scikit-learn) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.3->scikit-learn) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17.3->scikit-learn) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17.3->scikit-learn) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17.3->scikit-learn) (2024.2.0)\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"# Testing cell \n","metadata":{}},{"cell_type":"code","source":"import os\nimport torch\nfrom torch.amp import autocast\nfrom torch.utils.data import DataLoader\nfrom tqdm import tqdm\nfrom transformers import BlipProcessor, BlipForQuestionAnswering\nfrom accelerate import Accelerator\nimport time\nfrom sklearn.metrics import f1_score\nfrom bert_score import score as bert_score_fn\n\n# Step 1: Set environment variable to disable tokenizer parallelism warning\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n\n# Initialize Accelerator\naccelerator = Accelerator()\ndevice = accelerator.device\n\n# Load model and processor\nload_path = \"/kaggle/input/blip-finetunedmodel-versions/model_latest_v4\"\nmodel = BlipForQuestionAnswering.from_pretrained(load_path)\nprocessor = BlipProcessor.from_pretrained(load_path)\n\n# Prepare model for distributed inference\nmodel = accelerator.prepare(model)\n\n# Load dataset\ntest_json_dir = \"/kaggle/input/master-test/test_dataset\"\ntest_image_dir = \"/kaggle/input/abo-dataset\"\ntest_dataset = VQADataset(\n    json_dirs=test_json_dir,\n    base_img_path=test_image_dir,\n    processor=processor\n)\n\n# DataLoader setup\nbatch_size = 100\nnum_workers = 12\ntest_loader = DataLoader(\n    test_dataset,\n    batch_size=batch_size,\n    shuffle=False,\n    num_workers=num_workers,\n    pin_memory=True,\n    persistent_workers=True\n)\n\n# Evaluation setup\nmodel.eval()\ncorrect = 0\ntotal = 0\nbatch_count = len(test_loader)\n\npredicted_all = []\ntrue_all = []\n\nstart_time = time.time()\n\n# Evaluation loop\nwith torch.no_grad():\n    for batch in tqdm(test_loader, total=batch_count, desc=\"Evaluating\"):\n        pixel_values = batch[\"pixel_values\"].to(device)\n        input_ids = batch[\"input_ids\"].to(device)\n        attention_mask = batch[\"attention_mask\"].to(device)\n        answers = batch[\"labels\"]\n\n        with autocast(device_type=device.type, dtype=torch.float16):\n            generated_ids = model.generate(\n                input_ids=input_ids,\n                pixel_values=pixel_values,\n                attention_mask=attention_mask,\n                max_length=20,\n                do_sample=False,\n                num_beams=1\n            )\n\n        predicted_answers = processor.batch_decode(generated_ids, skip_special_tokens=True)\n        decoded_answers = [\n            processor.tokenizer.decode(ans, skip_special_tokens=True)\n            if isinstance(ans, torch.Tensor) else ans\n            for ans in answers\n        ]\n\n        for pred, true_ans_str in zip(predicted_answers, decoded_answers):\n            pred_clean = pred.strip().lower()\n            true_clean = true_ans_str.strip().lower()\n\n            predicted_all.append(pred_clean)\n            true_all.append(true_clean)\n\n            if pred_clean == true_clean:\n                correct += 1\n            total += 1\n\nend_time = time.time()\nelapsed = end_time - start_time\n\n# Compute Exact Match\nexact_match = 100 * correct / total\n\n# Compute BERTScore\nP, R, F1 = bert_score_fn(predicted_all, true_all, lang=\"en\", verbose=True)\nbert_score_f1 = F1.mean().item()\nbert_score_precision = P.mean().item()\nbert_score_recall = R.mean().item()\n\n# Print all metrics\nprint(f\"\\n📊 Evaluation Metrics:\")\nprint(f\"✅ Exact Match (EM): {exact_match:.2f}%\")\nprint(f\"🤖 BERTScore - Precision: {bert_score_precision:.4f}\")\nprint(f\"🤖 BERTScore - Recall:    {bert_score_recall:.4f}\")\nprint(f\"🤖 BERTScore - F1:        {bert_score_f1:.4f}\")\nprint(f\"\\n⏱️ Total Evaluation Time: {elapsed:.2f} seconds for {total} samples.\")\nprint(f\"⚡ Inference Speed: {total / elapsed:.2f} it/sec\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T15:56:22.801625Z","iopub.execute_input":"2025-05-08T15:56:22.802000Z","iopub.status.idle":"2025-05-08T19:54:39.475489Z","shell.execute_reply.started":"2025-05-08T15:56:22.801958Z","shell.execute_reply":"2025-05-08T19:54:39.474579Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/4.56k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df86e9d787e3499dad1c926611803c27"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.54G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3942b5ddcbe84138982ecb4080ed9815"}},"metadata":{}},{"name":"stderr","text":"Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n","output_type":"stream"},{"name":"stdout","text":"📁 Scanning JSON folders: /kaggle/input/master-test/test_dataset\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"✅ Loaded 482036 samples.\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|██████████| 4821/4821 [3:50:35<00:00,  2.87s/it]  \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b3920d3cd1024d70b79981a9601b3b9a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"199edd25f07c420080025c93913b487f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"12e4ac0ba8e64306b941a5c37c01c2b9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c08991eccf0a426084df7f2376f463e8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1109ee6c105142a88b17ddc7e89135b4"}},"metadata":{}},{"name":"stderr","text":"Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d5647a6532bc4bbe82bb65440e2aaf13"}},"metadata":{}},{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"calculating scores...\ncomputing bert embedding.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/436 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be5ac16dd7464696852571c6cfd85972"}},"metadata":{}},{"name":"stdout","text":"computing greedy matching.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/7532 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"61a976f240af419d9788aae6fc54c7db"}},"metadata":{}},{"name":"stderr","text":"Warning: Empty reference sentence detected; setting raw BERTScores to 0.\nWarning: Empty reference sentence detected; setting raw BERTScores to 0.\nWarning: Empty reference sentence detected; setting raw BERTScores to 0.\nWarning: Empty candidate sentence detected; setting raw BERTscores to 0.\nWarning: Empty reference sentence detected; setting raw BERTScores to 0.\nWarning: Empty reference sentence detected; setting raw BERTScores to 0.\nWarning: Empty reference sentence detected; setting raw BERTScores to 0.\nWarning: Empty reference sentence detected; setting raw BERTScores to 0.\nWarning: Empty reference sentence detected; setting raw BERTScores to 0.\nWarning: Empty reference sentence detected; setting raw BERTScores to 0.\nWarning: Empty reference sentence detected; setting raw BERTScores to 0.\nWarning: Empty reference sentence detected; setting raw BERTScores to 0.\nWarning: Empty reference sentence detected; setting raw BERTScores to 0.\nWarning: Empty reference sentence detected; setting raw BERTScores to 0.\nWarning: Empty reference sentence detected; setting raw BERTScores to 0.\nWarning: Empty reference sentence detected; setting raw BERTScores to 0.\nWarning: Empty reference sentence detected; setting raw BERTScores to 0.\nWarning: Empty reference sentence detected; setting raw BERTScores to 0.\nWarning: Empty reference sentence detected; setting raw BERTScores to 0.\nWarning: Empty reference sentence detected; setting raw BERTScores to 0.\nWarning: Empty reference sentence detected; setting raw BERTScores to 0.\nWarning: Empty reference sentence detected; setting raw BERTScores to 0.\n","output_type":"stream"},{"name":"stdout","text":"done in 112.28 seconds, 4293.09 sentences/sec\n\n📊 Evaluation Metrics:\n✅ Exact Match (EM): 18.95%\n🤖 BERTScore - Precision: 0.9571\n🤖 BERTScore - Recall:    0.9360\n🤖 BERTScore - F1:        0.9455\n\n⏱️ Total Evaluation Time: 13835.83 seconds for 482036 samples.\n⚡ Inference Speed: 34.84 it/sec\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"print(f\"✅ Exact Match (EM): {exact_match:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T19:54:39.476746Z","iopub.execute_input":"2025-05-08T19:54:39.477010Z","iopub.status.idle":"2025-05-08T19:54:39.482581Z","shell.execute_reply.started":"2025-05-08T19:54:39.476974Z","shell.execute_reply":"2025-05-08T19:54:39.481828Z"}},"outputs":[{"name":"stdout","text":"✅ Exact Match (EM): 18.95%\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"from bert_score import score as bert_score_fn\n\nP, R, F1 = bert_score_fn(predicted_all, true_all, lang=\"en\", verbose=True)\nbert_score_precision = P.mean().item()\nbert_score_recall = R.mean().item()\nbert_score_f1 = F1.mean().item()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T19:54:39.483346Z","iopub.execute_input":"2025-05-08T19:54:39.483540Z","iopub.status.idle":"2025-05-08T19:56:32.853759Z","shell.execute_reply.started":"2025-05-08T19:54:39.483525Z","shell.execute_reply":"2025-05-08T19:56:32.852904Z"}},"outputs":[{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"calculating scores...\ncomputing bert embedding.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/436 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1d38bc2ea5464c369a130f6e998d8375"}},"metadata":{}},{"name":"stdout","text":"computing greedy matching.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/7532 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"654b7c6cf24b485c84bcdd277cdd9226"}},"metadata":{}},{"name":"stderr","text":"Warning: Empty reference sentence detected; setting raw BERTScores to 0.\nWarning: Empty reference sentence detected; setting raw BERTScores to 0.\nWarning: Empty reference sentence detected; setting raw BERTScores to 0.\nWarning: Empty candidate sentence detected; setting raw BERTscores to 0.\nWarning: Empty reference sentence detected; setting raw BERTScores to 0.\nWarning: Empty reference sentence detected; setting raw BERTScores to 0.\nWarning: Empty reference sentence detected; setting raw BERTScores to 0.\nWarning: Empty reference sentence detected; setting raw BERTScores to 0.\nWarning: Empty reference sentence detected; setting raw BERTScores to 0.\nWarning: Empty reference sentence detected; setting raw BERTScores to 0.\nWarning: Empty reference sentence detected; setting raw BERTScores to 0.\nWarning: Empty reference sentence detected; setting raw BERTScores to 0.\nWarning: Empty reference sentence detected; setting raw BERTScores to 0.\nWarning: Empty reference sentence detected; setting raw BERTScores to 0.\nWarning: Empty reference sentence detected; setting raw BERTScores to 0.\nWarning: Empty reference sentence detected; setting raw BERTScores to 0.\nWarning: Empty reference sentence detected; setting raw BERTScores to 0.\nWarning: Empty reference sentence detected; setting raw BERTScores to 0.\nWarning: Empty reference sentence detected; setting raw BERTScores to 0.\nWarning: Empty reference sentence detected; setting raw BERTScores to 0.\nWarning: Empty reference sentence detected; setting raw BERTScores to 0.\nWarning: Empty reference sentence detected; setting raw BERTScores to 0.\n","output_type":"stream"},{"name":"stdout","text":"done in 112.43 seconds, 4287.47 sentences/sec\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"print(f\"🤖 BERTScore - Precision: {bert_score_precision:.4f}\")\nprint(f\"🤖 BERTScore - Recall:    {bert_score_recall:.4f}\")\nprint(f\"🤖 BERTScore - F1:        {bert_score_f1:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T19:56:32.854819Z","iopub.execute_input":"2025-05-08T19:56:32.855156Z","iopub.status.idle":"2025-05-08T19:56:32.859875Z","shell.execute_reply.started":"2025-05-08T19:56:32.855112Z","shell.execute_reply":"2025-05-08T19:56:32.859238Z"}},"outputs":[{"name":"stdout","text":"🤖 BERTScore - Precision: 0.9571\n🤖 BERTScore - Recall:    0.9360\n🤖 BERTScore - F1:        0.9455\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"print(f\"\\n⏱️ Total Evaluation Time: {elapsed:.2f} seconds for {total} samples.\")\nprint(f\"⚡ Inference Speed: {total / elapsed:.2f} it/sec\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T19:56:32.860697Z","iopub.execute_input":"2025-05-08T19:56:32.860913Z","iopub.status.idle":"2025-05-08T19:56:32.877754Z","shell.execute_reply.started":"2025-05-08T19:56:32.860895Z","shell.execute_reply":"2025-05-08T19:56:32.877007Z"}},"outputs":[{"name":"stdout","text":"\n⏱️ Total Evaluation Time: 13835.83 seconds for 482036 samples.\n⚡ Inference Speed: 34.84 it/sec\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}