{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install transformers accelerate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-02T19:45:34.902703Z",
     "iopub.status.busy": "2025-05-02T19:45:34.902081Z",
     "iopub.status.idle": "2025-05-02T19:45:45.707910Z",
     "shell.execute_reply": "2025-05-02T19:45:45.707165Z",
     "shell.execute_reply.started": "2025-05-02T19:45:34.902672Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84f56e915a6a48caae1ca38e266bf4ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/445 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f81a5c57e962409f976aa575fb7d3b71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/592 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc48abfe9a534516af598f31e7c68955",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6282db6c15934480813ddc01a008d479",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23ec92d67f234f928aae33c01a25d6b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "830013ef75be45e088fd7479a110e7f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/4.56k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c4afdc74c654d2bbd42123b4213272e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.54G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "# ---- BLIP-1 ----\n",
    "from transformers import BlipProcessor, BlipForQuestionAnswering\n",
    "\n",
    "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-vqa-base\")\n",
    "model = BlipForQuestionAnswering.from_pretrained(\"Salesforce/blip-vqa-base\").to(\"cuda\")\n",
    "\n",
    "img_url = 'https://storage.googleapis.com/sfr-vision-language-research/BLIP/demo.jpg'\n",
    "raw_image = Image.open(requests.get(img_url, stream=True).raw).convert('RGB')\n",
    "\n",
    "question = \"how many humans are in the picture?\"\n",
    "inputs = processor(raw_image, question, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "out = model.generate(**inputs)\n",
    "print(\"BLIP-1 Answer:\", processor.decode(out[0], skip_special_tokens=True))\n",
    "\n",
    "\n",
    "# ---- BLIP-2 with OPT-2.7B ----\n",
    "# from transformers import Blip2Processor, Blip2ForConditionalGeneration\n",
    "# processor = Blip2Processor.from_pretrained(\"Salesforce/blip2-opt-2.7b\")\n",
    "# model = Blip2ForConditionalGeneration.from_pretrained(\"Salesforce/blip2-opt-2.7b\", torch_dtype=torch.float16).to(\"cuda\")\n",
    "# inputs = processor(raw_image, question, return_tensors=\"pt\").to(\"cuda\", torch.float16)\n",
    "# out = model.generate(**inputs)\n",
    "# print(\"BLIP-2 OPT-2.7B Answer:\", processor.decode(out[0], skip_special_tokens=True))\n",
    "\n",
    "\n",
    "# ---- BLIP-2 with FLAN-T5 XL ----\n",
    "# from transformers import Blip2Processor, Blip2ForConditionalGeneration\n",
    "# processor = Blip2Processor.from_pretrained(\"Salesforce/blip2-flan-t5-xl\")\n",
    "# model = Blip2ForConditionalGeneration.from_pretrained(\"Salesforce/blip2-flan-t5-xl\", torch_dtype=torch.float16).to(\"cuda\")\n",
    "# inputs = processor(raw_image, question, return_tensors=\"pt\").to(\"cuda\", torch.float16)\n",
    "# out = model.generate(**inputs, max_new_tokens=50)\n",
    "# print(\"BLIP-2 FLAN-T5 XL Answer:\", processor.decode(out[0], skip_special_tokens=True))\n",
    "\n",
    "\n",
    "# ---- BLIP-2 with FLAN-T5 XXL ----\n",
    "# from transformers import Blip2Processor, Blip2ForConditionalGeneration\n",
    "# processor = Blip2Processor.from_pretrained(\"Salesforce/blip2-flan-t5-xxl\")\n",
    "# model = Blip2ForConditionalGeneration.from_pretrained(\"Salesforce/blip2-flan-t5-xxl\", torch_dtype=torch.float16).to(\"cuda\")\n",
    "# inputs = processor(raw_image, question, return_tensors=\"pt\").to(\"cuda\", torch.float16)\n",
    "# out = model.generate(**inputs, max_new_tokens=50)\n",
    "# print(\"BLIP-2 FLAN-T5 XXL Answer:\", processor.decode(out[0], skip_special_tokens=True))\n",
    "\n",
    "\n",
    "# ---- BakLLaVA ----\n",
    "# from transformers import AutoProcessor, AutoModelForVision2Seq\n",
    "# processor = AutoProcessor.from_pretrained(\"LanguageBind/BakLLaVA-1\")\n",
    "# model = AutoModelForVision2Seq.from_pretrained(\"LanguageBind/BakLLaVA-1\", torch_dtype=torch.float16).to(\"cuda\")\n",
    "# inputs = processor(text=question, images=raw_image, return_tensors=\"pt\").to(\"cuda\", torch.float16)\n",
    "# out = model.generate(**inputs, max_new_tokens=50)\n",
    "# print(\"BakLLaVA Answer:\", processor.batch_decode(out, skip_special_tokens=True)[0])\n",
    "\n",
    "\n",
    "# ---- Qwen-VL ----\n",
    "# from transformers import AutoProcessor, AutoModelForVision2Seq\n",
    "# processor = AutoProcessor.from_pretrained(\"Qwen/Qwen-VL\")\n",
    "# model = AutoModelForVision2Seq.from_pretrained(\"Qwen/Qwen-VL\", torch_dtype=torch.float16).to(\"cuda\")\n",
    "# inputs = processor(raw_image, question, return_tensors=\"pt\").to(\"cuda\", torch.float16)\n",
    "# out = model.generate(**inputs)\n",
    "# print(\"Qwen-VL Answer:\", processor.batch_decode(out, skip_special_tokens=True)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T19:45:19.902261Z",
     "iopub.status.busy": "2025-05-02T19:45:19.901565Z",
     "iopub.status.idle": "2025-05-02T19:45:22.893248Z",
     "shell.execute_reply": "2025-05-02T19:45:22.892315Z",
     "shell.execute_reply.started": "2025-05-02T19:45:19.902223Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rouge_score in /usr/local/lib/python3.11/dist-packages (0.1.2)\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.4.0)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge_score) (3.9.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.26.4)\n",
      "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.17.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (8.1.8)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (4.67.1)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (2.4.1)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->rouge_score) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->rouge_score) (2022.1.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->rouge_score) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->rouge_score) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->rouge_score) (2024.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install rouge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T19:45:50.650609Z",
     "iopub.status.busy": "2025-05-02T19:45:50.650036Z",
     "iopub.status.idle": "2025-05-02T19:45:53.907561Z",
     "shell.execute_reply": "2025-05-02T19:45:53.906537Z",
     "shell.execute_reply.started": "2025-05-02T19:45:50.650584Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!pip install bert-score rouge-score nltk sacrebleu --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T13:36:01.112492Z",
     "iopub.status.busy": "2025-05-02T13:36:01.112164Z",
     "iopub.status.idle": "2025-05-02T13:36:13.325500Z",
     "shell.execute_reply": "2025-05-02T13:36:13.324783Z",
     "shell.execute_reply.started": "2025-05-02T13:36:01.112467Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: git+https://github.com/neulab/BARTScore.git does not appear to be a Python project: neither 'setup.py' nor 'pyproject.toml' found.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/neulab/BARTScore.git --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T13:40:38.063499Z",
     "iopub.status.busy": "2025-05-02T13:40:38.063219Z",
     "iopub.status.idle": "2025-05-02T13:40:45.494611Z",
     "shell.execute_reply": "2025-05-02T13:40:45.493692Z",
     "shell.execute_reply.started": "2025-05-02T13:40:38.063479Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'BARTScore'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remote: Enumerating objects: 220, done.\u001b[K\n",
      "remote: Counting objects: 100% (26/26), done.\u001b[K\n",
      "remote: Compressing objects: 100% (12/12), done.\u001b[K\n",
      "remote: Total 220 (delta 18), reused 14 (delta 14), pack-reused 194 (from 1)\u001b[K\n",
      "Receiving objects: 100% (220/220), 101.98 MiB | 23.79 MiB/s, done.\n",
      "Resolving deltas: 100% (47/47), done.\n",
      "Updating files: 100% (192/192), done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/neulab/BARTScore.git\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T13:49:33.243596Z",
     "iopub.status.busy": "2025-05-02T13:49:33.243315Z",
     "iopub.status.idle": "2025-05-02T13:49:33.248315Z",
     "shell.execute_reply": "2025-05-02T13:49:33.247608Z",
     "shell.execute_reply.started": "2025-05-02T13:49:33.243578Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "setup_code = \"\"\"\n",
    "from setuptools import setup, find_packages\n",
    "\n",
    "setup(\n",
    "    name='bart_score',\n",
    "    version='0.1.0',\n",
    "    description='BARTScore: Evaluating Text Generation with BART',\n",
    "    author='Neulab',\n",
    "    url='https://github.com/neulab/BARTScore',\n",
    "    packages=find_packages(),\n",
    "    install_requires=[\n",
    "        'torch>=1.7.0',\n",
    "        'transformers>=4.0.0',\n",
    "        'scipy',\n",
    "        'numpy',\n",
    "        'tqdm',\n",
    "    ],\n",
    "    classifiers=[\n",
    "        'Programming Language :: Python :: 3',\n",
    "        'License :: OSI Approved :: MIT License',\n",
    "    ],\n",
    "    python_requires='>=3.6',\n",
    ")\n",
    "\"\"\"\n",
    "with open(\"BARTScore/setup.py\", \"w\") as f:\n",
    "    f.write(setup_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T13:49:36.131371Z",
     "iopub.status.busy": "2025-05-02T13:49:36.130836Z",
     "iopub.status.idle": "2025-05-02T13:49:44.643347Z",
     "shell.execute_reply": "2025-05-02T13:49:44.642415Z",
     "shell.execute_reply.started": "2025-05-02T13:49:36.131350Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./BARTScore\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from bart_score==0.1.0) (2.5.1+cu124)\n",
      "Requirement already satisfied: transformers>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from bart_score==0.1.0) (4.51.1)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from bart_score==0.1.0) (1.15.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from bart_score==0.1.0) (1.26.4)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from bart_score==0.1.0) (4.67.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->bart_score==0.1.0) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->bart_score==0.1.0) (4.13.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->bart_score==0.1.0) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->bart_score==0.1.0) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->bart_score==0.1.0) (2025.3.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->bart_score==0.1.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->bart_score==0.1.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->bart_score==0.1.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->bart_score==0.1.0) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->bart_score==0.1.0) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->bart_score==0.1.0) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->bart_score==0.1.0) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->bart_score==0.1.0) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->bart_score==0.1.0) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->bart_score==0.1.0) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->bart_score==0.1.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->bart_score==0.1.0) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->bart_score==0.1.0) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.0->bart_score==0.1.0) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.7.0->bart_score==0.1.0) (1.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.0.0->bart_score==0.1.0) (0.30.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.0.0->bart_score==0.1.0) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.0.0->bart_score==0.1.0) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.0.0->bart_score==0.1.0) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers>=4.0.0->bart_score==0.1.0) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.0.0->bart_score==0.1.0) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.0.0->bart_score==0.1.0) (0.5.2)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->bart_score==0.1.0) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->bart_score==0.1.0) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->bart_score==0.1.0) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->bart_score==0.1.0) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->bart_score==0.1.0) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->bart_score==0.1.0) (2.4.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.7.0->bart_score==0.1.0) (3.0.2)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->bart_score==0.1.0) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->bart_score==0.1.0) (2022.1.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->bart_score==0.1.0) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->bart_score==0.1.0) (2024.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.0.0->bart_score==0.1.0) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.0.0->bart_score==0.1.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.0.0->bart_score==0.1.0) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.0.0->bart_score==0.1.0) (2025.1.31)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->bart_score==0.1.0) (2024.2.0)\n",
      "Building wheels for collected packages: bart_score\n",
      "  Building wheel for bart_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for bart_score: filename=bart_score-0.1.0-py3-none-any.whl size=5317 sha256=2a3dbd4d92663b0b085bc62880bb303dae4166683ce00fa5ad1c98d9246df6c6\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-y57o9zvq/wheels/98/01/d3/10d9ca6b2865ade955e5f3c526e4a9b480ab24cea364919527\n",
      "Successfully built bart_score\n",
      "Installing collected packages: bart_score\n",
      "Successfully installed bart_score-0.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install ./BARTScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T19:46:04.722974Z",
     "iopub.status.busy": "2025-05-02T19:46:04.722243Z",
     "iopub.status.idle": "2025-05-03T05:00:12.316226Z",
     "shell.execute_reply": "2025-05-03T05:00:12.314132Z",
     "shell.execute_reply.started": "2025-05-02T19:46:04.722940Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📘 Resuming from saved progress (573 Q&A pairs done).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/144321 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "100%|██████████| 144321/144321 [9:13:06<00:00,  4.35it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📏 Calculating BERTScore...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da1f21e6512946e8832dfad14d50608c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "965a8505834344fd81d00040c1103a49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7eb84f869c5a42af9b28e1d0b332512e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee1784b3960e4eb2b7d39a0ec68b1b0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edea33264b5a49bbb2dc39ec72d83460",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b023f5973fb745d8aaf6376b5eda1d9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4bb3729832f47d6b02b460034f999c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/231 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c17f86b32b32476885ce73a73ca2a15c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2256 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 40.28 seconds, 3582.62 sentences/sec\n",
      "\n",
      "✅ Evaluation complete: Full Dataset\n",
      "Accuracy:       0.1901\n",
      "F1 Score:       0.0152\n",
      "BLEU:           0.0000\n",
      "ROUGE-L:        0.2122\n",
      "BARTScore:      -5.8426\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "mean() received an invalid combination of arguments - got (dtype=NoneType, out=NoneType, axis=NoneType, ), but expected one of:\n * (*, torch.dtype dtype = None)\n * (tuple of ints dim, bool keepdim = False, *, torch.dtype dtype = None)\n * (tuple of names dim, bool keepdim = False, *, torch.dtype dtype = None)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_31/3067238669.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;31m# ---- MAIN EXECUTION ----\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0mfiltered_qa_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_qa_data\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcompleted_set\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m \u001b[0mevaluate_qa_pairs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_qa_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Full Dataset\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"full_dataset_results.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_31/3067238669.py\u001b[0m in \u001b[0;36mevaluate_qa_pairs\u001b[0;34m(pairs, description, csv_filename)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"ROUGE-L:        {np.mean(rougeL_scores):.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"BARTScore:      {np.mean(bart_scores):.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"BERTScore (P/R/F1): {np.mean(bert_P):.4f} / {np.mean(bert_R):.4f} / {np.mean(bert_F1):.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;31m# ---- MAIN EXECUTION ----\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mmean\u001b[0;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[1;32m   3500\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3501\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3502\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3504\u001b[0m     return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "\u001b[0;31mTypeError\u001b[0m: mean() received an invalid combination of arguments - got (dtype=NoneType, out=NoneType, axis=NoneType, ), but expected one of:\n * (*, torch.dtype dtype = None)\n * (tuple of ints dim, bool keepdim = False, *, torch.dtype dtype = None)\n * (tuple of names dim, bool keepdim = False, *, torch.dtype dtype = None)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import csv\n",
    "import pickle\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from rouge_score import rouge_scorer\n",
    "from BARTScore.bart_score import BARTScorer\n",
    "from bert_score import score as bert_score\n",
    "import numpy as np\n",
    "\n",
    "# --- Define Paths ---\n",
    "json_folder_path = \"/kaggle/input/new-batch/Batch_1\"\n",
    "image_base_path = \"/kaggle/input/abo-small/small\"\n",
    "all_qa_data_path = \"/kaggle/working/all_qa_data.pkl\"\n",
    "progress_file = \"/kaggle/working/progress.json\"\n",
    "\n",
    "# from your_model_library import model, processor\n",
    "\n",
    "# ---- LOAD CACHED DATA OR BUILD ----\n",
    "if os.path.exists(all_qa_data_path):\n",
    "    with open(all_qa_data_path, \"rb\") as f:\n",
    "        all_qa_data = pickle.load(f)\n",
    "else:\n",
    "    print(\"🔄 Processing Q&A data from JSON files...\")\n",
    "    all_qa_data = []\n",
    "    for json_file in os.listdir(json_folder_path):\n",
    "        if not json_file.endswith(\".json\"):\n",
    "            continue\n",
    "        json_path = os.path.join(json_folder_path, json_file)\n",
    "        with open(json_path, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        raw_path = data[\"image_path\"].replace(\"\\\\\", \"/\")\n",
    "        path_parts = raw_path.split(\"/\")[-2:]\n",
    "        image_rel_path = \"/\".join(path_parts)\n",
    "        full_img_path = os.path.join(image_base_path, image_rel_path)\n",
    "\n",
    "        if not os.path.exists(full_img_path):\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            raw_image = Image.open(full_img_path).convert(\"RGB\")\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "        for idx, qa_pair in enumerate(data.get(\"qa_pairs\", [])):\n",
    "            question = qa_pair.get(\"question\", \"\").strip()\n",
    "            answer = qa_pair.get(\"answer\", \"\").strip()\n",
    "            if question and answer:\n",
    "                all_qa_data.append((json_file, idx, full_img_path, question, answer))\n",
    "\n",
    "    with open(all_qa_data_path, \"wb\") as f:\n",
    "        pickle.dump(all_qa_data, f)\n",
    "    print(\"✅ Q&A data saved to disk.\")\n",
    "\n",
    "# ---- LOAD PROGRESS ----\n",
    "if os.path.exists(progress_file):\n",
    "    try:\n",
    "        with open(progress_file, \"r\") as f:\n",
    "            completed_set = set(tuple(x) for x in json.load(f))\n",
    "        print(f\"📘 Resuming from saved progress ({len(completed_set)} Q&A pairs done).\")\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error reading progress: {e}\")\n",
    "        completed_set = set()\n",
    "else:\n",
    "    completed_set = set()\n",
    "    print(\"Progress file does not exist. Starting fresh.\")\n",
    "\n",
    "# ---- EVALUATION FUNCTION ----\n",
    "def evaluate_qa_pairs(pairs, description, csv_filename):\n",
    "    y_true, y_pred = [], []\n",
    "    all_preds, all_gts = [], []\n",
    "    bleu_scores, rougeL_scores, bart_scores = [], [], []\n",
    "\n",
    "    rouge = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n",
    "    bart_scorer = BARTScorer(device=\"cuda\", checkpoint=\"facebook/bart-large-cnn\")\n",
    "\n",
    "    with open(f\"/kaggle/working/{csv_filename}\", 'w', newline='') as csvfile:\n",
    "        fieldnames = ['json_file', 'question_id', 'question', 'ground_truth', 'predicted_answer']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "        for json_file, idx, img_path, question, ground_truth in tqdm(pairs):\n",
    "            if (json_file, idx) in completed_set:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                raw_image = Image.open(img_path).convert(\"RGB\")\n",
    "                inputs = processor(raw_image, question, return_tensors=\"pt\").to(\"cuda\")\n",
    "                out = model.generate(**inputs)\n",
    "                answer = processor.decode(out[0], skip_special_tokens=True)\n",
    "            except Exception as e:\n",
    "                print(f\"[ERROR] {json_file} Q{idx+1} → {e}\")\n",
    "                answer = \"ERROR\"\n",
    "\n",
    "            gt = ground_truth.strip().lower()\n",
    "            pred = answer.strip().lower()\n",
    "            y_true.append(gt)\n",
    "            y_pred.append(pred)\n",
    "            all_preds.append(pred)\n",
    "            all_gts.append(gt)\n",
    "\n",
    "            # BLEU\n",
    "            bleu_scores.append(sentence_bleu([gt.split()], pred.split()))\n",
    "\n",
    "            # ROUGE-L\n",
    "            rougeL_scores.append(rouge.score(gt, pred)['rougeL'].fmeasure)\n",
    "\n",
    "            # BARTScore\n",
    "            bart_scores.append(bart_scorer.score([pred], [gt])[0])\n",
    "\n",
    "            writer.writerow({\n",
    "                'json_file': json_file,\n",
    "                'question_id': idx,\n",
    "                'question': question,\n",
    "                'ground_truth': ground_truth,\n",
    "                'predicted_answer': answer\n",
    "            })\n",
    "\n",
    "            completed_set.add((json_file, idx))\n",
    "            with open(progress_file, \"w\") as f:\n",
    "                json.dump(list(completed_set), f)\n",
    "\n",
    "    # BERTScore (compute outside loop)\n",
    "    print(\"📏 Calculating BERTScore...\")\n",
    "    bert_P, bert_R, bert_F1 = bert_score(all_preds, all_gts, lang='en', verbose=True)\n",
    "    bert_P = P.numpy()\n",
    "    bert_R = R.numpy()\n",
    "    bert_F1 = F1.numpy()\n",
    "\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred, average=\"macro\")\n",
    "\n",
    "    print(f\"\\n✅ Evaluation complete: {description}\")\n",
    "    print(f\"Accuracy:       {acc:.4f}\")\n",
    "    print(f\"F1 Score:       {f1:.4f}\")\n",
    "    print(f\"BLEU:           {np.mean(bleu_scores):.4f}\")\n",
    "    print(f\"ROUGE-L:        {np.mean(rougeL_scores):.4f}\")\n",
    "    print(f\"BARTScore:      {np.mean(bart_scores):.4f}\")\n",
    "    print(f\"BERTScore (P/R/F1): {np.mean(bert_P):.4f} / {np.mean(bert_R):.4f} / {np.mean(bert_F1):.4f}\")\n",
    "\n",
    "# ---- MAIN EXECUTION ----\n",
    "filtered_qa_data = [item for item in all_qa_data if (item[0], item[1]) not in completed_set]\n",
    "evaluate_qa_pairs(filtered_qa_data, \"Full Dataset\", \"full_dataset_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T05:04:01.219290Z",
     "iopub.status.busy": "2025-05-03T05:04:01.219012Z",
     "iopub.status.idle": "2025-05-03T05:04:46.079244Z",
     "shell.execute_reply": "2025-05-03T05:04:46.078261Z",
     "shell.execute_reply.started": "2025-05-03T05:04:01.219269Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 Reading predictions from /kaggle/working/full_dataset_results.csv...\n",
      "✅ Loaded 144284 Q&A pairs.\n",
      "🔍 Computing BERTScore...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d7706b3d13b412096d69c9ba55314ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/268 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05685bd10f404156898dcf3e2d73bba5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2255 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 43.18 seconds, 3341.14 sentences/sec\n",
      "\n",
      "🎯 BERTScore Results:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "mean() received an invalid combination of arguments - got (dtype=NoneType, out=NoneType, axis=NoneType, ), but expected one of:\n * (*, torch.dtype dtype = None)\n * (tuple of ints dim, bool keepdim = False, *, torch.dtype dtype = None)\n * (tuple of names dim, bool keepdim = False, *, torch.dtype dtype = None)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_31/3273540232.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# --- OUTPUT RESULTS ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n🎯 BERTScore Results:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Precision:  {np.mean(P):.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Recall:     {np.mean(R):.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"F1 Score:   {np.mean(F1):.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mmean\u001b[0;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[1;32m   3500\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3501\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3502\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3504\u001b[0m     return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "\u001b[0;31mTypeError\u001b[0m: mean() received an invalid combination of arguments - got (dtype=NoneType, out=NoneType, axis=NoneType, ), but expected one of:\n * (*, torch.dtype dtype = None)\n * (tuple of ints dim, bool keepdim = False, *, torch.dtype dtype = None)\n * (tuple of names dim, bool keepdim = False, *, torch.dtype dtype = None)\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from bert_score import score as bert_score\n",
    "import numpy as np\n",
    "\n",
    "# --- CONFIG ---\n",
    "csv_path = \"/kaggle/working/full_dataset_results.csv\"  # or any result file\n",
    "bert_lang = \"en\"  # language for BERTScore\n",
    "\n",
    "# --- LOAD CSV DATA ---\n",
    "ground_truths = []\n",
    "predictions = []\n",
    "\n",
    "print(f\"📂 Reading predictions from {csv_path}...\")\n",
    "with open(csv_path, 'r') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        gt = row['ground_truth'].strip()\n",
    "        pred = row['predicted_answer'].strip()\n",
    "        if gt and pred:\n",
    "            ground_truths.append(gt)\n",
    "            predictions.append(pred)\n",
    "\n",
    "print(f\"✅ Loaded {len(ground_truths)} Q&A pairs.\")\n",
    "\n",
    "# --- COMPUTE BERTSCORE ---\n",
    "print(\"🔍 Computing BERTScore...\")\n",
    "P, R, F1 = bert_score(predictions, ground_truths, lang=bert_lang, verbose=True)\n",
    "P = P.numpy()\n",
    "R = R.numpy()\n",
    "F1 = F1.numpy()\n",
    "# --- OUTPUT RESULTS ---\n",
    "print(\"\\n🎯 BERTScore Results:\")\n",
    "print(f\"Precision:  {np.mean(P):.4f}\")\n",
    "print(f\"Recall:     {np.mean(R):.4f}\")\n",
    "print(f\"F1 Score:   {np.mean(F1):.4f}\")\n",
    "\n",
    "# --- OPTIONAL: SAVE DETAILED SCORES ---\n",
    "with open(\"/kaggle/working/bertscore_details.csv\", \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"Ground Truth\", \"Prediction\", \"Precision\", \"Recall\", \"F1\"])\n",
    "    for gt, pred, p, r, f1 in zip(ground_truths, predictions, P, R, F1):\n",
    "        writer.writerow([gt, pred, f\"{p:.4f}\", f\"{r:.4f}\", f\"{f1:.4f}\"])\n",
    "\n",
    "print(\"📁 Saved detailed BERTScore results to bertscore_details.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-03T05:05:32.765065Z",
     "iopub.status.busy": "2025-05-03T05:05:32.764483Z",
     "iopub.status.idle": "2025-05-03T05:06:16.714755Z",
     "shell.execute_reply": "2025-05-03T05:06:16.714175Z",
     "shell.execute_reply.started": "2025-05-03T05:05:32.765041Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66f2f312e1074211af6a3d6538bd222f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/268 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "124e05c19190430bb025690c95322870",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2255 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 42.46 seconds, 3398.20 sentences/sec\n",
      "\n",
      "🎯 BERTScore Results:\n",
      "Precision:  0.9379\n",
      "Recall:     0.9164\n",
      "F1 Score:   0.9259\n"
     ]
    }
   ],
   "source": [
    "P, R, F1 = bert_score(predictions, ground_truths, lang=bert_lang, verbose=True)\n",
    "P = P.numpy()\n",
    "R = R.numpy()\n",
    "F1 = F1.numpy()\n",
    "# --- OUTPUT RESULTS ---\n",
    "print(\"\\n🎯 BERTScore Results:\")\n",
    "print(f\"Precision:  {np.mean(P):.4f}\")\n",
    "print(f\"Recall:     {np.mean(R):.4f}\")\n",
    "print(f\"F1 Score:   {np.mean(F1):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T13:51:26.532090Z",
     "iopub.status.busy": "2025-05-02T13:51:26.531789Z",
     "iopub.status.idle": "2025-05-02T13:51:34.708216Z",
     "shell.execute_reply": "2025-05-02T13:51:34.707665Z",
     "shell.execute_reply.started": "2025-05-02T13:51:26.532069Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8795e75abbe4fcc891737785ae728c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ca6c49f007242aaa558b115347b731c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9ce973a69c844d8b63947a7ee04a669",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "285568ea0492405a8d5d92ad2f5b17c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.58k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7aab1d47ec24f759d2f4929cfd9ef60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc427988b09046a78af29eaa880ee253",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from BARTScore.bart_score import BARTScorer\n",
    "\n",
    "bart_scorer = BARTScorer(device=\"cuda\", checkpoint=\"facebook/bart-large-cnn\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7189537,
     "sourceId": 11472097,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7310940,
     "sourceId": 11650039,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
